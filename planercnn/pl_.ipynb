{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ackages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:12:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      " #define CHECK_FLOAT(x) AT_ASSERTM(x.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == torch::ScalarType::Float, #x \" must be float Tensor\")\n",
      "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:219:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[K’\n",
      " #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n",
      "                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:238:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[K’\n",
      " #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n",
      "                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:285:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K’\n",
      "   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {       \\\n",
      "       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:447:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K’\n",
      "     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(cond, __VA_ARGS__));     \\\n",
      "                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:12:24:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_ASSERTM\u001b[m\u001b[K’\n",
      " #define CHECK_FLOAT(x) \u001b[01;36m\u001b[KAT_ASSERTM\u001b[m\u001b[K(x.type().scalarType() == torch::ScalarType::Float, #x \" must be float Tensor\")\n",
      "                        \u001b[01;36m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:73:31:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KCHECK_FLOAT\u001b[m\u001b[K’\n",
      "     CHECK_INPUT(grads_image); \u001b[01;36m\u001b[KC\u001b[m\u001b[KHECK_FLOAT(grads_image); CHECK_DIMS(grads_image);\n",
      "                               \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:277:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
      "                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:90:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "         grads.data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n",
      "                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:363:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
      "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:91:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "         boxes.data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n",
      "                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:363:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
      "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:92:29:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "         box_index.data<int>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n",
      "                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:363:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
      "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:95:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "         grads_image.data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n",
      "                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kroi_align/src/crop_and_resize_gpu.cpp:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:363:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n",
      "       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c roi_align/src/cuda/crop_and_resize_kernel.cu -o build/temp.linux-x86_64-3.6/roi_align/src/cuda/crop_and_resize_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O2 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=crop_and_resize_gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/roi_align/src/crop_and_resize_gpu.o build/temp.linux-x86_64-3.6/roi_align/src/cuda/crop_and_resize_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/roi_align/crop_and_resize_gpu.cpython-36m-x86_64-linux-gnu.so\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/roi_align\n",
      "copying build/lib.linux-x86_64-3.6/roi_align/roi_align.py -> build/bdist.linux-x86_64/egg/roi_align\n",
      "copying build/lib.linux-x86_64-3.6/roi_align/crop_and_resize_gpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/roi_align\n",
      "copying build/lib.linux-x86_64-3.6/roi_align/crop_and_resize.py -> build/bdist.linux-x86_64/egg/roi_align\n",
      "copying build/lib.linux-x86_64-3.6/roi_align/crop_and_resize_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/roi_align\n",
      "copying build/lib.linux-x86_64-3.6/roi_align/__init__.py -> build/bdist.linux-x86_64/egg/roi_align\n",
      "byte-compiling build/bdist.linux-x86_64/egg/roi_align/roi_align.py to roi_align.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/roi_align/crop_and_resize.py to crop_and_resize.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/roi_align/__init__.py to __init__.cpython-36.pyc\n",
      "creating stub loader for roi_align/crop_and_resize_cpu.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for roi_align/crop_and_resize_gpu.cpython-36m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/roi_align/crop_and_resize_cpu.py to crop_and_resize_cpu.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/roi_align/crop_and_resize_gpu.py to crop_and_resize_gpu.cpython-36.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying roi_align.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying roi_align.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying roi_align.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying roi_align.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying roi_align.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "roi_align.__pycache__.crop_and_resize_cpu.cpython-36: module references __file__\n",
      "roi_align.__pycache__.crop_and_resize_gpu.cpython-36: module references __file__\n",
      "creating dist\n",
      "creating 'dist/roi_align-0.0.2-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing roi_align-0.0.2-py3.6-linux-x86_64.egg\n",
      "creating /usr/local/lib/python3.6/dist-packages/roi_align-0.0.2-py3.6-linux-x86_64.egg\n",
      "Extracting roi_align-0.0.2-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
      "Adding roi-align 0.0.2 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.6/dist-packages/roi_align-0.0.2-py3.6-linux-x86_64.egg\n",
      "Processing dependencies for roi-align==0.0.2\n",
      "Searching for torch==1.7.0+cu101\n",
      "Best match: torch 1.7.0+cu101\n",
      "Adding torch 1.7.0+cu101 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
      "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for dataclasses==0.8\n",
      "Best match: dataclasses 0.8\n",
      "Adding dataclasses 0.8 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for future==0.16.0\n",
      "Best match: future 0.16.0\n",
      "Adding future 0.16.0 to easy-install.pth file\n",
      "Installing futurize script to /usr/local/bin\n",
      "Installing pasteurize script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for typing-extensions==3.7.4.3\n",
      "Best match: typing-extensions 3.7.4.3\n",
      "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for numpy==1.18.5\n",
      "Best match: numpy 1.18.5\n",
      "Adding numpy 1.18.5 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.6 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Finished processing dependencies for roi-align==0.0.2\n"
     ]
    }
   ],
   "source": [
    "!bash install_roi_ext.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import PlaneRCNNDetector\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_pkl.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)\n",
    "with open('options_pkl.pkl','rb') as f:\n",
    "    options = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PlaneRCNNDetector(options, config, modelType='final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (6): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (7): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (8): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (9): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (10): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (11): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (12): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (13): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (14): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (15): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (16): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (17): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (18): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (19): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (20): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (21): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (22): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (C5): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n        (bn1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n          (1): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n        (bn1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (padding2): SamePad2d\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n        (bn2): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n        (bn3): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (P6): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (P5_conv1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n    (P5_conv2): Sequential(\n      (0): SamePad2d\n      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n    )\n    (P4_conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n    (P4_conv2): Sequential(\n      (0): SamePad2d\n      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n    )\n    (P3_conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n    (P3_conv2): Sequential(\n      (0): SamePad2d\n      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n    )\n    (P2_conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n    (P2_conv2): Sequential(\n      (0): SamePad2d\n      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n    )\n  )\n  (rpn): RPN(\n    (padding): SamePad2d\n    (conv_shared): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n    (relu): ReLU(inplace=True)\n    (conv_class): Conv2d(512, 6, kernel_size=(1, 1), stride=(1, 1))\n    (softmax): Softmax(dim=2)\n    (conv_bbox): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (coordinates): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n  (classifier): Classifier(\n    (conv1): Conv2d(320, 1024, kernel_size=(7, 7), stride=(1, 1))\n    (bn1): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n    (bn2): BatchNorm2d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (linear_class): Linear(in_features=1024, out_features=8, bias=True)\n    (softmax): Softmax(dim=1)\n    (linear_bbox): Linear(in_features=1024, out_features=32, bias=True)\n    (linear_parameters): Linear(in_features=1024, out_features=24, bias=True)\n  )\n  (mask): Mask(\n    (padding): SamePad2d\n    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n    (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n    (bn2): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n    (bn3): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n    (bn4): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n    (conv5): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n    (sigmoid): Sigmoid()\n    (relu): ReLU(inplace=True)\n  )\n  (depth): Depth(\n    (conv1): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv2): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv4): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv5): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (deconv1): Sequential(\n      (0): Upsample(scale_factor=2.0, mode=nearest)\n      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n    (deconv2): Sequential(\n      (0): Upsample(scale_factor=2.0, mode=nearest)\n      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n    (deconv3): Sequential(\n      (0): Upsample(scale_factor=2.0, mode=nearest)\n      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n    (deconv4): Sequential(\n      (0): Upsample(scale_factor=2.0, mode=nearest)\n      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n    (deconv5): Sequential(\n      (0): Upsample(scale_factor=2.0, mode=nearest)\n      (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n    (depth_pred): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}